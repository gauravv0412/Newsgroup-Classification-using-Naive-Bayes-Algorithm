{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting stop-words to remove from text.......added more words to it after studying data....\n",
    "extra = ['a','b','c','d', 'e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z', 'must', 'still', 'might', 'mr', 'one','like', 'many', 'say', 'much', 'first', 'want', 'right', 'article', 'anyone', 'nntppostinghost', 'really', 'something', 'since', 'come', 'anything', 'else', 'let', 'see', 'may','giving,' 'good', 'now', 'think', 'use' , 'writes','also', 'can', 'get', 'will', 'never', 'without', 'sure', 'back', 'another', 'etc', 'however', 'just', 'maxaxaxaxaxaxaxaxaxaxaxaxaxaxax', 'know', 'new', 'even', 'make', 'us']    \n",
    "\n",
    "# This is to remove punctuation marks .......\n",
    "removables = str.maketrans(\"\",\"\",string.punctuation + '0123456789')\n",
    "\n",
    "# location where stopwords are stored\n",
    "stop_words_location = open(path + '/stopwords_english.txt')\n",
    "text = stop_words_location.read()\n",
    "text = text.translate(removables)\n",
    "\n",
    "# Generating list of stopwords......\n",
    "stopwords = text.split('\\n')\n",
    "stopwords = stopwords + extra "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob  # For extracting files from a folder in one go...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of newsgroups: 20\n"
     ]
    }
   ],
   "source": [
    "# This 'folder' contains address of all folder 20_newsgroups.......\n",
    "folder = path + '/20_newsgroups/*'\n",
    "\n",
    "# This 'newsgroups' will contain list of all classes or folders in 20_newsgroups folder and SORTED to extract classes..\n",
    "newsgroups = glob.glob(folder)\n",
    "newsgroups = sorted(newsgroups)\n",
    "print('Total number of newsgroups:', len(newsgroups)) # just for clarity...\n",
    "\n",
    "y = []\n",
    "tar = 0          # just an iterating variable....\n",
    "\n",
    "# Making a dataframe of document_path and classes...... later used for train_test_split\n",
    "dataframe = pd.DataFrame()\n",
    "\n",
    "\n",
    "# To show the name of predicted class in testing phase.\n",
    "idx_to_newsclass = {}\n",
    "\n",
    "\n",
    "# Now extracting documents group by group with their respective class and adding them to dataframe\n",
    "for newsgroup in newsgroups :\n",
    "    documents = glob.glob(newsgroup +'/*')\n",
    "    ls = documents\n",
    "    dataframe = dataframe.append(ls)\n",
    "    y += [tar for i in range(len(ls))]\n",
    "    idx_to_newsclass[tar] = newsgroup.split('/')[-1]\n",
    "    tar = tar + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19997, 1), 19997)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape, len(y) # just for clarity....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "# now using train_test_split to divide the dataframe into training and testing part\n",
    "# Using loop to make sure that training_dataset contains atleast one document from each class....\n",
    "from sklearn.model_selection import train_test_split\n",
    "i = 1\n",
    "while(True):\n",
    "    training_dataframe, testing_dataframe, y_train, y_test = train_test_split(dataframe, y, random_state = i)\n",
    "    if len(set(y_train)) == 20:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "# just for clarity....\n",
    "print(i, sorted(set(y_train))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14997, 1), (5000, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe.shape, testing_dataframe.shape       # just for clarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This extract_total_words function will extract words and their count from each document in dataframe(training one) \n",
    "# and add them to total_words dict....\n",
    "\n",
    "# This is used only for calculating top 5000 words later...\n",
    "\n",
    "# total_words is a dictionary containing keys as words and values as count of occurances of those words...it is\n",
    "# universal dictionary for whole training data.....\n",
    "\n",
    "def extract_total_words(dataframe):  \n",
    "    total_words = {}\n",
    "    \n",
    "#     This list helps in removing lines of headers, footers...\n",
    "    ignore_words = ['Xref','newsanswers','Path', 'talks', \n",
    "                    'newsseicmuedu','spoolmuedu','From','Newsgroups','Subject',\n",
    "                    'Summary','Keywords','MessageID','Date','Expires','Followup','FollowupTO'\n",
    "                    'Distribution','Organization','Approved','Supersedes','Lines',\n",
    "                    'Archivename', 'Version', 'NNTPPostingHost', 'XNewsreader']\n",
    "    \n",
    "#     for removing punctuation marks and digits from news article\n",
    "    removables = str.maketrans(\"\",\"\",string.punctuation + '0123456789')\n",
    "    for i in range(len(dataframe)) :\n",
    "#         just for estimating how much time is left...... \n",
    "        if i % 1000 == 0 :                       \n",
    "            print(int(i*100/len(dataframe)), '% completed')\n",
    "        \n",
    "#         encoding is changed to avoid errors..... reading file...\n",
    "        file = open(dataframe.iloc[i,0], encoding=\"ISO-8859-1\")   \n",
    "\n",
    "        line = file.readline()\n",
    "#         Now headers are being removed from documents....\n",
    "        while ':' in line:\n",
    "            line = file.readline()\n",
    "            continue\n",
    "        while line:   \n",
    "#             Removing stop_words,numbers,useless text\n",
    "            line = line.translate(removables)    \n",
    "\n",
    "#             Splitting line in a list of words\n",
    "            line = line.lower()\n",
    "            words = line.split()                \n",
    "            \n",
    "#             Now adding of words and updating their count in total_words dict....\n",
    "            for word in words:\n",
    "                if word not in stopwords:\n",
    "                    total_words[word] = total_words.get(word, 0) + 1\n",
    "\n",
    "            line = file.readline()\n",
    "    print(100, '% completed')\n",
    "    return total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % completed\n",
      "6 % completed\n",
      "13 % completed\n",
      "20 % completed\n",
      "26 % completed\n",
      "33 % completed\n",
      "40 % completed\n",
      "46 % completed\n",
      "53 % completed\n",
      "60 % completed\n",
      "66 % completed\n",
      "73 % completed\n",
      "80 % completed\n",
      "86 % completed\n",
      "93 % completed\n",
      "100 % completed\n"
     ]
    }
   ],
   "source": [
    "total_words = extract_total_words(training_dataframe) # explained above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128906"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_words)       # just for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I have total_words dict which contain count of all words in training_dataframe...and dataset which contains list of all the dictionaries document wise containing words and its count....\n",
    "### Now I will extract top 5000 words which will become features of my dataset....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_words_count will contain list of all words sorted in descending order of their count values......\n",
    "top_words_count = sorted([(v,k) for (k,v) in total_words.items()], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " ['people',\n",
       "  'time',\n",
       "  'good',\n",
       "  'way',\n",
       "  'two',\n",
       "  'system',\n",
       "  'god',\n",
       "  'used',\n",
       "  'said',\n",
       "  'go'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now extracting important 5000 words....\n",
    "top_words = [v for k,v in top_words_count[0:5000]]\n",
    "\n",
    "# features of my dataset to be created in next cell...\n",
    "len(top_words), top_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates actual dataset which contains features as top_words and rows as documents....\n",
    "def create_dataset(dataframe, top_words) :\n",
    "    dataset = []\n",
    "    removables = str.maketrans(\"\",\"\",string.punctuation + '0123456789')\n",
    "    for i in range(len(dataframe)) :\n",
    "        if i % 1000 == 0 :                       \n",
    "            print(int(i*100/len(dataframe)), '% completed')\n",
    "            \n",
    "#         encoding is changed to avoid errors..... reading file...\n",
    "        file = open(dataframe.iloc[i,0], encoding=\"ISO-8859-1\")  \n",
    "\n",
    "#         Now headers are being removed from documents....\n",
    "        line = file.readline()\n",
    "        \n",
    "#         Now headers are being removed from documents....\n",
    "        while ':' in line:\n",
    "            line = file.readline()\n",
    "            continue\n",
    "        \n",
    "        temp = {}\n",
    "        while line:   \n",
    "#             Removing punctuation\n",
    "            line = line.translate(removables)   \n",
    "            line = line.lower()\n",
    "        \n",
    "#             Splitting line in a list of words\n",
    "            words = line.split()                \n",
    "\n",
    "#             Now adding top_words and updating their count in respective dictionaries is being performed....\n",
    "            for word in words:\n",
    "                if word in top_words:\n",
    "                    temp[word] = temp.get(word, 0) + 1\n",
    "\n",
    "            line = file.readline()\n",
    "            \n",
    "        dataset.append(temp)\n",
    "\n",
    "#         Adding dictionary for this document in dataset...\n",
    "    print('100% completed')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % completed\n",
      "6 % completed\n",
      "13 % completed\n",
      "20 % completed\n",
      "26 % completed\n",
      "33 % completed\n",
      "40 % completed\n",
      "46 % completed\n",
      "53 % completed\n",
      "60 % completed\n",
      "66 % completed\n",
      "73 % completed\n",
      "80 % completed\n",
      "86 % completed\n",
      "93 % completed\n",
      "100% completed\n"
     ]
    }
   ],
   "source": [
    "# this is taking 2-3 mins\n",
    "training_dataset = create_dataset(training_dataframe, top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % completed\n",
      "20 % completed\n",
      "40 % completed\n",
      "60 % completed\n",
      "80 % completed\n",
      "100% completed\n"
     ]
    }
   ],
   "source": [
    "testing_dataset = create_dataset(testing_dataframe, top_words)    # this is taking 2-3 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_dataset), type(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14997, 5000), (5000, 5000))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe out of dataset dictionary...\n",
    "training_dataset = pd.DataFrame(training_dataset, columns = top_words)\n",
    "testing_dataset = pd.DataFrame(testing_dataset, columns = top_words)\n",
    "training_dataset.shape, testing_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing NaN values by 0......\n",
    "training_dataset.replace(np.nan,0.0, inplace = True)\n",
    "testing_dataset.replace(np.nan,0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people</th>\n",
       "      <th>time</th>\n",
       "      <th>good</th>\n",
       "      <th>way</th>\n",
       "      <th>two</th>\n",
       "      <th>system</th>\n",
       "      <th>god</th>\n",
       "      <th>used</th>\n",
       "      <th>said</th>\n",
       "      <th>go</th>\n",
       "      <th>...</th>\n",
       "      <th>punished</th>\n",
       "      <th>providence</th>\n",
       "      <th>pretend</th>\n",
       "      <th>precision</th>\n",
       "      <th>powered</th>\n",
       "      <th>possession</th>\n",
       "      <th>politically</th>\n",
       "      <th>pluto</th>\n",
       "      <th>pirates</th>\n",
       "      <th>personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   people  time  good  way  two  system  god  used  said   go  ...  punished  \\\n",
       "0     1.0   0.0   0.0  2.0  1.0     0.0  0.0   1.0   0.0  0.0  ...       0.0   \n",
       "1     0.0   0.0   0.0  0.0  0.0     0.0  1.0   0.0   0.0  0.0  ...       0.0   \n",
       "2     2.0   1.0   0.0  1.0  0.0     0.0  0.0   0.0   0.0  0.0  ...       0.0   \n",
       "3     0.0   0.0   0.0  0.0  0.0     0.0  0.0   0.0   0.0  0.0  ...       0.0   \n",
       "4     0.0   0.0   0.0  0.0  0.0     2.0  0.0   1.0   0.0  0.0  ...       0.0   \n",
       "\n",
       "   providence  pretend  precision  powered  possession  politically  pluto  \\\n",
       "0         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "1         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "2         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "3         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "4         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "\n",
       "   pirates  personality  \n",
       "0      0.0          0.0  \n",
       "1      0.0          0.0  \n",
       "2      0.0          0.0  \n",
       "3      0.0          0.0  \n",
       "4      0.0          0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for clarity......\n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people</th>\n",
       "      <th>time</th>\n",
       "      <th>good</th>\n",
       "      <th>way</th>\n",
       "      <th>two</th>\n",
       "      <th>system</th>\n",
       "      <th>god</th>\n",
       "      <th>used</th>\n",
       "      <th>said</th>\n",
       "      <th>go</th>\n",
       "      <th>...</th>\n",
       "      <th>punished</th>\n",
       "      <th>providence</th>\n",
       "      <th>pretend</th>\n",
       "      <th>precision</th>\n",
       "      <th>powered</th>\n",
       "      <th>possession</th>\n",
       "      <th>politically</th>\n",
       "      <th>pluto</th>\n",
       "      <th>pirates</th>\n",
       "      <th>personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   people  time  good  way  two  system  god  used  said   go  ...  punished  \\\n",
       "0     0.0   0.0   0.0  0.0  0.0     0.0  0.0   0.0   0.0  0.0  ...       0.0   \n",
       "1     2.0   0.0   0.0  0.0  1.0     0.0  0.0   0.0   0.0  0.0  ...       0.0   \n",
       "2     0.0   0.0   0.0  0.0  0.0     0.0  0.0   1.0   0.0  0.0  ...       0.0   \n",
       "3     0.0   3.0   0.0  0.0  0.0     0.0  0.0   0.0   0.0  1.0  ...       0.0   \n",
       "4     0.0   0.0   3.0  0.0  0.0     0.0  0.0   0.0   0.0  0.0  ...       0.0   \n",
       "\n",
       "   providence  pretend  precision  powered  possession  politically  pluto  \\\n",
       "0         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "1         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "2         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "3         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "4         0.0      0.0        0.0      0.0         0.0          0.0    0.0   \n",
       "\n",
       "   pirates  personality  \n",
       "0      0.0          0.0  \n",
       "1      0.0          0.0  \n",
       "2      0.0          0.0  \n",
       "3      0.0          0.0  \n",
       "4      0.0          0.0  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for clarity.....\n",
    "testing_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Inbuilt Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.fit(training_dataset, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8339667933586717"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# My score on training dataset\n",
    "alg.score(training_dataset, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7684"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.score(testing_dataset, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = alg.predict(testing_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69       261\n",
      "           1       0.66      0.66      0.66       248\n",
      "           2       0.68      0.71      0.69       253\n",
      "           3       0.69      0.68      0.68       260\n",
      "           4       0.74      0.79      0.76       266\n",
      "           5       0.83      0.77      0.80       265\n",
      "           6       0.80      0.76      0.78       252\n",
      "           7       0.76      0.81      0.78       223\n",
      "           8       0.83      0.92      0.87       293\n",
      "           9       0.91      0.91      0.91       245\n",
      "          10       0.93      0.93      0.93       247\n",
      "          11       0.87      0.88      0.88       248\n",
      "          12       0.75      0.74      0.74       239\n",
      "          13       0.88      0.81      0.85       236\n",
      "          14       0.85      0.86      0.86       238\n",
      "          15       0.73      0.86      0.79       233\n",
      "          16       0.69      0.82      0.75       255\n",
      "          17       0.90      0.82      0.86       258\n",
      "          18       0.63      0.55      0.59       228\n",
      "          19       0.55      0.33      0.41       252\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.77      0.77      0.76      5000\n",
      "weighted avg       0.77      0.77      0.76      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predicted))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my own implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns the array of probabilities of each class...... will be called in fit function....\n",
    "\n",
    "# y_classes is y_true of training data.....\n",
    "\n",
    "def classes_prob(y_classes) :\n",
    "    y_pb = [0 for i in range(len(set(y_classes)))]  \n",
    "    \n",
    "    for i in range(len(set(y_classes))) : \n",
    "        y_pb[i] = y_classes.count(sorted(list(set(y_classes)))[i]) / len(y_classes)  \n",
    "    \n",
    "    return y_pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a fit function..... It will create a probability table in which there are 20 rows each for one class\n",
    "# and features are top_words...This dataframe contains probability of a word given that it belongs to some particular class.\n",
    "\n",
    "# dataset is training_dataset and y_classes is y_true....\n",
    "\n",
    "def fit(dataset, y_classes) :\n",
    "    prob_table = pd.DataFrame()\n",
    "    for ai in sorted(set(y_classes)) :\n",
    "        ls = np.array([0.0 for i in range(len(dataset.columns))])\n",
    "        for i in range(len(dataset)) :\n",
    "            if y_classes[i] == ai :\n",
    "                ls += np.array(dataset.iloc[i])\n",
    "        prob_table = prob_table.append([list(ls)], ignore_index=True)\n",
    "        print(prob_table.shape)\n",
    "    y_probs = classes_prob(y_classes)\n",
    "    \n",
    "    prob_table.columns = dataset.columns\n",
    "    prob_table += 1\n",
    "    for i in range(prob_table.shape[0]) :\n",
    "        prob_of_y_class = y_probs[i]\n",
    "        for j in range(prob_table.shape[1]) :\n",
    "            prob_table.iloc[i,j] = prob_table.iloc[i,j] / sum(prob_table.iloc[i])\n",
    "            prob_table.iloc[i,j] = prob_table.iloc[i,j] / prob_of_y_class \n",
    "        \n",
    "    return prob_table, y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a fit function..... It will create a probability table in which there are \n",
    "# 20 rows each for one class\n",
    "# and features are top_words...This dataframe contains probability of a \n",
    "# word given that it belongs to some particular class.\n",
    "\n",
    "# dataset is training_dataset and y_classes is y_true....\n",
    "\n",
    "def fit(dataset, y_classes) :\n",
    "    \n",
    "    prob_table = np.array([np.array([0.0 for _ in range(5000)]) for _ in range(20)])\n",
    "    \n",
    "    for i in range(len(dataset)) :\n",
    "        prob_table[y_classes[i]] = prob_table[y_classes[i]] + dataset.iloc[i]\n",
    "    \n",
    "    y_probs = classes_prob(y_classes)\n",
    "    \n",
    "    prob_table = pd.DataFrame(prob_table)\n",
    "    \n",
    "    prob_table.columns = dataset.columns\n",
    "    prob_table += 1\n",
    "    for i in range(prob_table.shape[0]) :\n",
    "        print(i*100/prob_table.shape[0], '% completed', end = '\\r')\n",
    "        prob_of_y_class = y_probs[i]\n",
    "#         print(prob_of_y_class)\n",
    "        prob_table.iloc[i] = prob_table.iloc[i] / sum(prob_table.iloc[i])\n",
    "#         print(prob_table.iloc[i])\n",
    "        prob_table.iloc[i] = np.log(prob_table.iloc[i]) - np.log(prob_of_y_class)\n",
    "    print('100% completed')\n",
    "    return prob_table, y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This predicts the class of each document..based on the prob_table returned from fit function...\n",
    "def predict(dataset, prob_table, y_probs) :\n",
    "    y_predicted = []\n",
    "    for i in range(len(dataset)) :\n",
    "        print(f'{i*100/len(dataset)}% completed', end = '\\r')\n",
    "        probs = [0.0 for i in range(len(prob_table))]\n",
    "        num_occur = np.array(dataset.iloc[i])\n",
    "        for j in range(len(prob_table)) :\n",
    "            prob = np.array(prob_table.iloc[j])\n",
    "            probs[j] += sum(list(num_occur*prob)) \n",
    "            probs[j] += np.log(y_probs[j])\n",
    "        y_predicted.append(probs.index(max(probs)))\n",
    "\n",
    "    print('100% completed')        \n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 % completed\r",
      "5.0 % completed\r",
      "10.0 % completed\r",
      "15.0 % completed\r",
      "20.0 % completed\r",
      "25.0 % completed\r",
      "30.0 % completed\r",
      "35.0 % completed\r",
      "40.0 % completed\r",
      "45.0 % completed\r",
      "50.0 % completed\r",
      "55.0 % completed\r",
      "60.0 % completed\r",
      "65.0 % completed\r",
      "70.0 % completed\r",
      "75.0 % completed\r",
      "80.0 % completed\r",
      "85.0 % completed\r",
      "90.0 % completed\r",
      "95.0 % completed\r",
      "100% completed\n"
     ]
    }
   ],
   "source": [
    "pb_table, y_pb = fit(training_dataset, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people</th>\n",
       "      <th>time</th>\n",
       "      <th>good</th>\n",
       "      <th>way</th>\n",
       "      <th>two</th>\n",
       "      <th>system</th>\n",
       "      <th>god</th>\n",
       "      <th>used</th>\n",
       "      <th>said</th>\n",
       "      <th>go</th>\n",
       "      <th>...</th>\n",
       "      <th>punished</th>\n",
       "      <th>providence</th>\n",
       "      <th>pretend</th>\n",
       "      <th>precision</th>\n",
       "      <th>powered</th>\n",
       "      <th>possession</th>\n",
       "      <th>politically</th>\n",
       "      <th>pluto</th>\n",
       "      <th>pirates</th>\n",
       "      <th>personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.774134</td>\n",
       "      <td>-2.498340</td>\n",
       "      <td>-2.560148</td>\n",
       "      <td>-2.573662</td>\n",
       "      <td>-3.226804</td>\n",
       "      <td>-2.743813</td>\n",
       "      <td>-1.633176</td>\n",
       "      <td>-3.359402</td>\n",
       "      <td>-2.658820</td>\n",
       "      <td>-3.389707</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.311331</td>\n",
       "      <td>-8.257242</td>\n",
       "      <td>-5.692292</td>\n",
       "      <td>-6.465482</td>\n",
       "      <td>-8.257242</td>\n",
       "      <td>-7.158629</td>\n",
       "      <td>-6.870947</td>\n",
       "      <td>-8.257242</td>\n",
       "      <td>-8.257242</td>\n",
       "      <td>-6.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.344829</td>\n",
       "      <td>-3.013471</td>\n",
       "      <td>-2.998204</td>\n",
       "      <td>-3.396122</td>\n",
       "      <td>-3.174483</td>\n",
       "      <td>-2.637497</td>\n",
       "      <td>-5.721522</td>\n",
       "      <td>-3.060724</td>\n",
       "      <td>-4.731123</td>\n",
       "      <td>-3.681301</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-5.578421</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-8.286471</td>\n",
       "      <td>-8.286471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.024564</td>\n",
       "      <td>-2.784613</td>\n",
       "      <td>-2.726344</td>\n",
       "      <td>-2.999458</td>\n",
       "      <td>-3.317912</td>\n",
       "      <td>-2.564140</td>\n",
       "      <td>-6.003489</td>\n",
       "      <td>-2.853606</td>\n",
       "      <td>-4.011059</td>\n",
       "      <td>-3.700904</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.795248</td>\n",
       "      <td>-7.795248</td>\n",
       "      <td>-7.795248</td>\n",
       "      <td>-7.102101</td>\n",
       "      <td>-7.102101</td>\n",
       "      <td>-7.795248</td>\n",
       "      <td>-7.795248</td>\n",
       "      <td>-7.795248</td>\n",
       "      <td>-6.185810</td>\n",
       "      <td>-7.795248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.223283</td>\n",
       "      <td>-2.621570</td>\n",
       "      <td>-2.764262</td>\n",
       "      <td>-3.204052</td>\n",
       "      <td>-2.525293</td>\n",
       "      <td>-2.026129</td>\n",
       "      <td>-5.778570</td>\n",
       "      <td>-2.975210</td>\n",
       "      <td>-4.029370</td>\n",
       "      <td>-3.501303</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-6.248574</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-7.858012</td>\n",
       "      <td>-7.858012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.105250</td>\n",
       "      <td>-2.796366</td>\n",
       "      <td>-2.922929</td>\n",
       "      <td>-3.067863</td>\n",
       "      <td>-2.955189</td>\n",
       "      <td>-1.951068</td>\n",
       "      <td>-5.967451</td>\n",
       "      <td>-2.741931</td>\n",
       "      <td>-3.888010</td>\n",
       "      <td>-3.281874</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.759211</td>\n",
       "      <td>-7.759211</td>\n",
       "      <td>-7.759211</td>\n",
       "      <td>-6.660598</td>\n",
       "      <td>-5.813300</td>\n",
       "      <td>-7.759211</td>\n",
       "      <td>-7.066063</td>\n",
       "      <td>-7.759211</td>\n",
       "      <td>-7.759211</td>\n",
       "      <td>-7.759211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     people      time      good       way       two    system       god  \\\n",
       "0 -1.774134 -2.498340 -2.560148 -2.573662 -3.226804 -2.743813 -1.633176   \n",
       "1 -3.344829 -3.013471 -2.998204 -3.396122 -3.174483 -2.637497 -5.721522   \n",
       "2 -3.024564 -2.784613 -2.726344 -2.999458 -3.317912 -2.564140 -6.003489   \n",
       "3 -3.223283 -2.621570 -2.764262 -3.204052 -2.525293 -2.026129 -5.778570   \n",
       "4 -3.105250 -2.796366 -2.922929 -3.067863 -2.955189 -1.951068 -5.967451   \n",
       "\n",
       "       used      said        go  ...  punished  providence   pretend  \\\n",
       "0 -3.359402 -2.658820 -3.389707  ... -6.311331   -8.257242 -5.692292   \n",
       "1 -3.060724 -4.731123 -3.681301  ... -8.286471   -8.286471 -8.286471   \n",
       "2 -2.853606 -4.011059 -3.700904  ... -7.795248   -7.795248 -7.795248   \n",
       "3 -2.975210 -4.029370 -3.501303  ... -7.858012   -7.858012 -7.858012   \n",
       "4 -2.741931 -3.888010 -3.281874  ... -7.759211   -7.759211 -7.759211   \n",
       "\n",
       "   precision   powered  possession  politically     pluto   pirates  \\\n",
       "0  -6.465482 -8.257242   -7.158629    -6.870947 -8.257242 -8.257242   \n",
       "1  -5.578421 -8.286471   -8.286471    -8.286471 -8.286471 -8.286471   \n",
       "2  -7.102101 -7.102101   -7.795248    -7.795248 -7.795248 -6.185810   \n",
       "3  -7.858012 -6.248574   -7.858012    -7.858012 -7.858012 -7.858012   \n",
       "4  -6.660598 -5.813300   -7.759211    -7.066063 -7.759211 -7.759211   \n",
       "\n",
       "   personality  \n",
       "0    -6.177800  \n",
       "1    -8.286471  \n",
       "2    -7.795248  \n",
       "3    -7.858012  \n",
       "4    -7.759211  \n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just for clarity.....\n",
    "pb_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% completeded\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(testing_dataset, pb_table, y_pb)      # This will take approx. 2-3 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.space\n",
      "rec.motorcycles\n",
      "rec.autos\n",
      "sci.med\n",
      "comp.graphics\n",
      "sci.space\n",
      "talk.politics.mideast\n",
      "misc.forsale\n",
      "sci.space\n",
      "comp.sys.mac.hardware\n"
     ]
    }
   ],
   "source": [
    "# just for clarity.....\n",
    "for pred in predictions[:10]:\n",
    "    print(idx_to_newsclass[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate score on my own predictions....\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7656"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.76      0.69       261\n",
      "           1       0.69      0.67      0.68       248\n",
      "           2       0.67      0.70      0.68       253\n",
      "           3       0.69      0.67      0.68       260\n",
      "           4       0.70      0.79      0.74       266\n",
      "           5       0.82      0.77      0.80       265\n",
      "           6       0.80      0.75      0.78       252\n",
      "           7       0.81      0.77      0.79       223\n",
      "           8       0.73      0.95      0.82       293\n",
      "           9       0.92      0.91      0.92       245\n",
      "          10       0.93      0.93      0.93       247\n",
      "          11       0.88      0.88      0.88       248\n",
      "          12       0.75      0.70      0.73       239\n",
      "          13       0.89      0.79      0.84       236\n",
      "          14       0.87      0.85      0.86       238\n",
      "          15       0.75      0.84      0.79       233\n",
      "          16       0.67      0.83      0.74       255\n",
      "          17       0.89      0.84      0.87       258\n",
      "          18       0.67      0.51      0.58       228\n",
      "          19       0.56      0.35      0.43       252\n",
      "\n",
      "    accuracy                           0.77      5000\n",
      "   macro avg       0.77      0.76      0.76      5000\n",
      "weighted avg       0.77      0.77      0.76      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------X----------------------------X-------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
